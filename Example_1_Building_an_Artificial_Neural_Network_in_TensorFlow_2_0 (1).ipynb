{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Example 1 - Building an Artificial Neural Network in TensorFlow 2.0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJr4nMgyb9oS"
      },
      "source": [
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://storage.googleapis.com/kaggle-datasets-images/2243/3791/9384af51de8baa77f6320901f53bd26b/dataset-cover.png\" />\n",
        "  Image source: https://www.kaggle.com/\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVF9I9v6Zipb"
      },
      "source": [
        "## Stage 1: Installing dependencies and setting up GPU environment ( coded in google colab and that .ipynb uploaded onto github)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS6fShx3Za4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a96a155f-3ae6-48a4-adb9-e8da17878ad1"
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0.alpha0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0.alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/66/32cffad095253219d53f6b6c2a436637bbe45ac4e7be0244557210dc3918/tensorflow_gpu-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (332.1MB)\n",
            "\u001b[K     |████████████████████████████████| 332.1MB 54kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.19.4)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.32.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.36.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.1.2)\n",
            "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 17.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.1.0)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 57.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (3.12.4)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.3.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.8.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0.alpha0) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha0) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha0) (1.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0.alpha0) (51.0.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha0) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha0) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha0) (3.7.4.3)\n",
            "Installing collected packages: keras-applications, tb-nightly, tf-estimator-nightly, tensorflow-gpu\n",
            "Successfully installed keras-applications-1.0.8 tb-nightly-1.14.0a20190301 tensorflow-gpu-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjlnjPnjWYFw"
      },
      "source": [
        "## Stage 2: Import dependencies for the project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt0-hrch6rZw"
      },
      "source": [
        "import numpy as np\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vv9AXUnZW78"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2OiUS-kWkJU"
      },
      "source": [
        "## Stage 3: Dataset preprocessing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdfoFiEEXYj1"
      },
      "source": [
        "### Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lCgz6UC8pKT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "679fdb24-c18b-482b-9fce-540a1a20288c"
      },
      "source": [
        "#Loading the Fashion Mnist dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYxeEHzDXdSs"
      },
      "source": [
        "### Image normalization\n",
        "\n",
        "We devide each image in the training and testing dataset with the maxiumum number of pixels (255).\n",
        "\n",
        "In this way each pixel will be in the rainge [0, 1]. By normalizing imaes we are making sure that our model (ANN) trains faster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvWzsB3G9IU8"
      },
      "source": [
        "X_train = X_train / 255.0 #each pixel can hold any value between 0 to 255, so to avoid extreme irregularity in data we normalize all the pixel values in our image by dividing with 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo--rpqo9ZtA"
      },
      "source": [
        "X_test = X_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBacLmGIX0Es"
      },
      "source": [
        "### Reshaping of the dataset\n",
        "\n",
        "Since we are using fully connected network, we reshape the training and testing subsets to be in the vector format. '**Flattening**' is converting the data into a 1-dimensional array for inputting it to the next layer. here each image is in 2d form i.e., 28 by 28 pixels which has to be converted into 1D form or vector form hence we take columns as 28by28 product as 784 where as the rows remains to be all (denoted as -1)  for upto 60000 training set images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Tao7pom-grn"
      },
      "source": [
        "#Since each image is 28x28, we simply use reshape the full dataset to [-1 (all elements), height * width]\n",
        "X_train = X_train.reshape(-1, 28*28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9MbMrg9-kr_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d1eb25f-b398-4369-eace-c454f5250a3f"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_duQGtbCTTL"
      },
      "source": [
        "#Reshape the testing subset in the same way\n",
        "X_test = X_test.reshape(-1, 28*28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5aDsaYSYmXD"
      },
      "source": [
        "## Stage 4: Building an Artificial Neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l30aZ6-GYtUP"
      },
      "source": [
        "### Defining the model\n",
        "\n",
        "Simply define an object of the Sequential model. ( why sequential is because a flattened layer supports only sequential inputs or a sequential model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmfogzmn9kqv"
      },
      "source": [
        "model = tf.keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNzLOAK5Y-mR"
      },
      "source": [
        "### Adding the first layer (Dense layer)\n",
        "\n",
        "Layer hyper-parameters:\n",
        "- number of units/neurons: 128 ( this means how many hidden neurons do we want to have in our 1st fully connected hidden layer)\n",
        "- activation function: ReLU ( is used to over come non linearity in the data as the images in this data set need not necessarily be linear or not in linear form)\n",
        "- input_shape: (784, ) (contains input layer or input vector that is fed into our neural network) flattened 2d into 1d aray\n",
        "\n",
        "...if we are planning to add 2nd hidden layer we dont need to give input_shape as it does not carry the intial input values and we can reduce or change the no of neurons or units to suppose 64 and try..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBsfDyGE-FX5"
      },
      "source": [
        "model.add(tf.keras.layers.Dense(units=128, activation='relu', input_shape=(784, ))) # we use dense class as we want to have full connections between our layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkZqWmhX6bUG"
      },
      "source": [
        "#model.add(tf.keras.Dense(units= 64, activation = 'relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vwqx1wZUa1rH"
      },
      "source": [
        "### Adding a Dropout layer \n",
        "\n",
        "Dropout is a Regularization technique where we randomly set neurons in a layer to zero. In this way, while training those neurons won't be updated. Because some percentage of neurons won't be updated the whole training process is long and we have less chance for overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAmpLPlr-pOX"
      },
      "source": [
        "model.add(tf.keras.layers.Dropout(0.2)) #this means we are choosing 20% i.e., 0.2 of our neurons to deactivated during back propagation in the learning process of\r\n",
        "# neurons in order to avoid overfitting"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGqvyDvNbzwN"
      },
      "source": [
        "### Adding the second layer (output layer)\n",
        "\n",
        "- units == number of classes (10 in the case of Fashion MNIST) ( this means how many neurons are we going to have in our output layer is 10 as we have 10 classes or varieties or types of costumes in our fashion mnist dataset)\n",
        "- activation = 'softmax' which means before getting final output values we will need to get or want neural network to return probabilties of each of the class and return the final class that has the highest probbility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmkUuF9Y-3mG"
      },
      "source": [
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rRsMjsvcOua"
      },
      "source": [
        "### Comiling the model\n",
        " Compile method is the another method of the sequential class\n",
        "- Optimizer: Adam ( An optimizer updates the weights through stochastic gradient descent way. One of the best optimizers is the adam optimizer, it can be used as default option as it is highly recommendable for optimizing purpose.\n",
        "- Loss: Sparse softmax (categorical) crossentropy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbW3xeRK_CrN"
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\r\n",
        "# when we have more than 2 categories or classes to predict unlike binary we use sparse_categorical_accuracy\r\n",
        "#loss is obtained by the comparision of our model predicted output or answers to the existing actual answers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dQOL_EtChrN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "e111d387-bee7-424f-ae7a-8f27a95c45ed"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kxIIFU1cany"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-_oLiE0_3A2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "9fb2fda4-f52d-4662-d3f5-16bb0d071904"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 0.5325 - accuracy: 0.8128\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.4013 - accuracy: 0.8537\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.3705 - accuracy: 0.8671\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.3467 - accuracy: 0.8733\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 6s 94us/sample - loss: 0.3327 - accuracy: 0.8772\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb870342ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mj23nxmtcrhd"
      },
      "source": [
        "### Model evaluation and prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nQCioOmAL7i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b277b331-a05f-494f-e283-4e8db20b8819"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 65us/sample - loss: 0.3490 - accuracy: 0.8736\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ozv2YVlxcx1h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb831b93-7fb5-4df0-ea65-99b3d4e2c631"
      },
      "source": [
        "print(\"Test accuracy: {}\".format(test_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.8736000061035156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Noi53-uq9yhl"
      },
      "source": [
        "## Stage 5 : Saving the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMFm-Z9I99R5"
      },
      "source": [
        "### Saving the architecture (topology) of the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT7pmXWO9xxM"
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"fashion_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UDk8L4A-CQX"
      },
      "source": [
        "### Saving network weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0ZOVcC498Mp"
      },
      "source": [
        "model.save_weights(\"fashion_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}